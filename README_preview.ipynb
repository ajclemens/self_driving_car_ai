{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Democratizing Autonomous Driving\n",
    "---\n",
    "### Problem Statement\n",
    "The existing self-driving car market is dominated by multi-billion dollar companies such as Alphabet, Tesla, Ford etc. Perceived barriers to entry include high costs, access to data, and technicality. A market with only big companies will result in monopoly/oligopoly where a few companies get to decide the price of the product, not the supply and demand relation. Consumers suffer greatly from monopoly as they don't have other options. In an effort to prevent this situation from happening, we would like to build a self-driving car model from scratch based on convolutional neural networks to showcase that self-driving is not as beyond reach for smaller companies, or even startups. In fact, it is possible to build a well-performed self-driving car model with relative small datasets, simple hardware requirement and a straightforward process. By doing this, we hope that more company executives will join the wave of self-driving rather than sit back and be the observants.\n",
    "\n",
    "  We will be exploring the following specific questions:\n",
    "1. Can we train a model using convolutional neural network(CNN) to keep the car in the lane and finish a track?\n",
    "2. Can we optimize the model to make the car drive more like a human (more smoothly), rather than swerve in the lane?\n",
    "3. Can we optimize the model to drive as fast as it could while still stay in the lane?\n",
    "4. Can we use a smaller dataset to achieve similar results as big datasets?\n",
    "5. Can we break through the hardware limitations of smaller companies?\n",
    "\n",
    "---\n",
    "\n",
    "### Contents\n",
    "\n",
    "* [Data Aquisition & Cleaning](#data_aquisition_and_cleaning)\n",
    "* [Exploratory Data Analysis](#exploratory_data_analysis)\n",
    "* [Image Preprocessing & Augmentation](#image_preprocessing_&_augmentation)\n",
    "* [Modeling and Tuning](#modeling_and_tuning)\n",
    "* [Evaluation](#evaluation)\n",
    "* [Findings and Recommendations](#findings_and_recommendations)\n",
    "* [Limitations and Next Steps](#limitations_and_next_steps)\n",
    "* [Technical Log](#technical_log)\n",
    "* [Software Requirements](#software_requirements)\n",
    "* [Acknowledgements and Contact](#acknowledgements_and_contact)\n",
    "\n",
    "---\n",
    "<a id='data_aquisition_and_cleaning'></a>\n",
    "### Data Aquisition & Cleaning\n",
    "\n",
    "We luckily found a driving simulator open sourced by Udacity which allows us easily collect data. Once we hit record button, we can control the car with WASD keyboard and the simulator will automatically generate a driving log which records images captured by three cameras placed left, center and right at the car front and the WASD inputs. In order to validate our hypothesis that even with smaller datasets, we can still build a well-performed model with CNN, we fed into our model with two different datasets: Udacity-released datasets which has over 9,000 rows of data and a self-generated dataset with only 1300+ rows. \n",
    "\n",
    "Thanks to the auto-generated driving log, there are not much data cleaning for us to do except for adding the columns for data and align the file path for the camera captures.\n",
    "\n",
    "---\n",
    "<a id='exploratory_data_analysis'></a>\n",
    "### Exploratory Data Analysis\n",
    "\n",
    "The EDA is based only on the Udacity-released dataset.\n",
    "\n",
    "The mean of steering angles is 0, with standard deviation of 0.16. We could tell that the data does not have big spread, which makes sense as too much steering should not be expected on a gentle track. The distribution of steering angles shows that 0 steering angle is the abosolute most frequent number, which confirms that the track requires mostly straight driving. A breakdown of the counts of steering angles per direction indicate that there are more left turns than right turns, which means the dataset would be baised to favorleft turns than right turns. Also, as going straight is the aboslute majority, driving straight would also be preferred. To mitigate these issues, image augmentation should be counsidered to use on our datasets, for i.e.: we should consider filp the images to create a more balanced set between turns. And limit the number of zero steerings in the sample. \n",
    "\n",
    "<img src='./charts/dist_of_steering_angles.png' style=\"float: left; width: 500px;\"/>                   \n",
    "<img src='./charts/count_of_steering.png' style=\"float:left; width: 500px;\"/>\n",
    "\n",
    "\n",
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "By exploring the captured images from the three cameras, we found that the images from the center camera have in fact contained all the information that left and right cameras have captured. Therefore we believe the images from the center camera should be sufficient to be the only input. However, images captured from left and right could serve as our assitance in correcting the steering of the car in case it goes off center. So we would also include those images, only to adjust the steering angles accordingly with a correction angle. \n",
    "\n",
    "Furthermore, the original images contain irrelevant info such as sky, grass and car front which are noise rather than signal for the model. We therefore decided to crop those out of the images before feeding them into the convolutional neural networks.\n",
    "\n",
    "![](./charts/neg_steer.png)\n",
    "![](./charts/zero_steer.png)\n",
    "![](./charts/pos_steer.png)\n",
    "\n",
    "---\n",
    "<a id='image_preprocessing_&_augmentation'></a>\n",
    "### Image Preprocessing & Augmentation\n",
    "\n",
    "To improve the quality of the data, image preprocessing and augmentation are applied. The preprocessing include cropping, resizing and converting the color space. Take cropping as an example, each image contains information irrelevant to the problem at hand, e.g. the sky, background, trees, hood of the car. The images are thus cropped to avoid feeding the neural network this superfluous information. Below is an example of how the images look after being cropped:\n",
    "\n",
    "<img src='./charts/before_after/before.png' style=\"float: left; width: 500px;\"/>                   \n",
    "<img src='./charts/before_after/after_crop.png' style=\"float:left; width: 500px;\"/>\n",
    "\n",
    "\n",
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "\n",
    "During model training, images are also augmented in the way of random flip, translation, shadow, or brighten transformation. Augmentation of this sort creates a more robust model that is less overfit on the training set, as we are artificially introducing variance into the training.\n",
    "\n",
    "Below are the examples of images to which random flip was applied:\n",
    "\n",
    "<img src='./charts/before_after/after_flip.png' style=\"width: 500px;\"/>                   \n",
    "\n",
    "\n",
    "Examples of images to which random brightness was applied:\n",
    "\n",
    "<img src='./charts/before_after/after_brightness.png' style=\"width: 1000px;\"/>                   \n",
    "\n",
    "Examples of images to which random shadow was applied:\n",
    "\n",
    "<img src='./charts/before_after/after_shadow.png' style=\"width: 1000px;\"/>  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<a id='modeling_and_tuning'></a>\n",
    "### Modeling and Tuning\n",
    "\n",
    "Our model is based on the NVIDIA model which explores the possibility of using only CNN regression.\n",
    "\n",
    "Baseline Model\n",
    "\n",
    "Best Model\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<a id='evaluation'></a>\n",
    "### Evaluation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "<a id='findings_and_recommendations'></a>\n",
    "### Findings and Recommendations\n",
    "\n",
    "  Answer the problem statement:\n",
    "> 1. Point 1...\n",
    "> 2. Point 2...\n",
    "> 3. Point 3...\n",
    "\n",
    "---\n",
    "<a id='limitations_and_next_steps'></a>\n",
    "### Limitations and Next Steps\n",
    "\n",
    "Limitations:\n",
    "Next Steps:\n",
    "\n",
    "---\n",
    "<a id='technical_log'></a>\n",
    "### Technical Log:\n",
    "#### Cloning and Debugging\n",
    "\n",
    "> * 10/27/2020 Pre-trained simulator is downloaded and run. First data collection.\n",
    "> * 10/28/2020 An updated version of Keras and a dated starter code lead to a rocky start full of error messages.\n",
    "> * 10/28/2020 After no success working in a virtual enviornment, Anthony brute force debugs *model.py* and *utils.py* from outdated dependencies.\n",
    "> * and then...\n",
    "\n",
    "#### Cloud Computing with GPU\n",
    "\n",
    "> * 10/28/2020 Anthony attempted running *model.py* on his local machine and reported 2-3 hours per epoch. The workload clearly needs to be shifted for reduced computation time as well as for practical reasons.\n",
    "> * 10/28/2020 Cloudy successfully imports *utils.py* to the cloud --> from utils import INPUT_SHAPE, batch_generator, and we successfully upload *model.py* in Google Colaboratory. \n",
    "> * 10/28/2020 Anthony runs 3 epochs overnight.\n",
    "> * 10/29/2020 Success! Three epochs were enough to start our self-driving car...a swerving and shifty self-driving car, but one none-the-less.\n",
    "\n",
    "#### Training the CNN\n",
    "\n",
    "> * 10/29/2020 Discuss training ...\n",
    "> * and then..\n",
    "> * and then...\n",
    "\n",
    "---\n",
    "<a id='software_requirements'></a>\n",
    "### Software Requirements:\n",
    "\n",
    "\n",
    "---\n",
    "<a id='acknowledgements_and_contact'></a>\n",
    "### Acknowledgements and Contact:\n",
    "\n",
    "External Resources:\n",
    "* [`How to Simulate a Self-Driving Car`] (YouTube): ([*source*](https://www.youtube.com/watch?v=EaY5QiZwSP4&t=1209s))\n",
    "* [`udacity/self-driving-car-sim`] (GitHub): ([*source*](https://github.com/udacity/self-driving-car-sim))\n",
    "* [`naokishibuya/car-behavioral-cloning`] (GitHub): ([*source*](https://github.com/naokishibuya/car-behavioral-cloning))\n",
    "* [`llSourcell/How_to_simulate_a_self_driving_car`] (GitHub): ([*source*](https://github.com/llSourcell/How_to_simulate_a_self_driving_car))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
